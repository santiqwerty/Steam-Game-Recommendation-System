{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los dataframes desde archivos parquet\n",
    "df_items = pd.read_parquet('../data/interim/parquet/final_items.parquet')\n",
    "df_games = pd.read_parquet('../data/interim/parquet/final_games.parquet')\n",
    "df_reviews = pd.read_parquet('../data/interim/parquet/final_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que la columna 'item_id' sea de tipo int\n",
    "df_items['item_id'] = df_items['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer merge: unir df_items y df_games en 'item_id' y 'id'\n",
    "merged_df_1 = pd.merge(df_items, df_games, left_on='item_id', right_on='id')\n",
    "\n",
    "# Segundo merge: unir el DataFrame resultante con df_reviews en 'user_id'\n",
    "final_merged_df = pd.merge(merged_df_1, df_reviews, on='user_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna item_id_y y renombrar item_id_x a item_id\n",
    "final_merged_df = final_merged_df.drop(columns=['item_id_y']).rename(columns={'item_id_x': 'item_id'})\n",
    "\n",
    "# Definir el nuevo orden de las columnas (mover las columnas de géneros al final para una mejor organización)\n",
    "\n",
    "new_column_order = [\n",
    "    'user_id', 'steam_id', 'item_id', 'developer', 'item_name', 'playtime_forever',\n",
    "    'app_name', 'id', 'price', 'release_year', 'funny', 'posted', \n",
    "    'helpful', 'recommend', 'sentiment_analysis',\n",
    "    # Mover las columnas de géneros al final\n",
    "    'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG',\n",
    "    'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle',\n",
    "    'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer',\n",
    "    'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult',\n",
    "    'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter',\n",
    "    'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox',\n",
    "    'Arcade'\n",
    "]\n",
    "\n",
    "# Reorganizar las columnas\n",
    "final_merged_df = final_merged_df.reindex(columns=new_column_order)\n",
    "\n",
    "# Seleccionar las columnas relevantes para análisis de género y tiempo de juego\n",
    "genre_playtime_df = final_merged_df[['user_id', 'playtime_forever', 'release_year', 'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG', 'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle', 'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer', 'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult', 'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter', 'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox', 'Arcade']]\n",
    "\n",
    "# Crear una copia y asegurando que 'release_year' es de tipo int\n",
    "genre_playtime_df = genre_playtime_df.copy()\n",
    "genre_playtime_df['release_year'] = genre_playtime_df['release_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando dataframes para análisis específicos\n",
    "\n",
    "recommendations_df = final_merged_df[['app_name', 'release_year', 'recommend', 'sentiment_analysis']]\n",
    "\n",
    "developer_df = final_merged_df[['developer', 'item_id', 'release_year', 'Free to Play']]\n",
    "\n",
    "userdata_df = final_merged_df[['user_id', 'price', 'recommend']]\n",
    "\n",
    "best_developer_year_df = final_merged_df[['developer', 'release_year', 'recommend']]\n",
    "\n",
    "developer_reviews_analysis_df = final_merged_df[['developer', 'sentiment_analysis']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save(endpoint_function, dataframe, column, output_filename):\n",
    "    \"\"\"\n",
    "    Precalcula datos utilizando una función de endpoint específica y los guarda en un archivo Parquet.\n",
    "    \n",
    "    Parameters:\n",
    "    endpoint_function (function): La función que procesará los datos.\n",
    "    dataframe (pd.DataFrame): El DataFrame que contiene los datos a procesar.\n",
    "    column (str): La columna que contiene los valores únicos para procesar.\n",
    "    output_filename (str): El nombre del archivo donde se guardarán los datos procesados.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Obtener los valores únicos en la columna especificada\n",
    "    unique_values = dataframe[column].unique()\n",
    "    \n",
    "    # Utilizar ThreadPoolExecutor para ejecutar las operaciones en paralelo\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Mapear la función endpoint a cada valor único\n",
    "        all_processed_data_list = list(executor.map(endpoint_function, unique_values))\n",
    "        \n",
    "    # Concatenar todos los datos procesados\n",
    "    all_processed_data = pd.concat(all_processed_data_list)\n",
    "    \n",
    "    # Establecer el índice del DataFrame resultante a la columna especificada\n",
    "    all_processed_data.set_index(column, inplace=True)\n",
    "    \n",
    "    # Guardar todos los datos procesados en un archivo Parquet\n",
    "    all_processed_data.to_parquet(output_filename)\n",
    "    \n",
    "    # Imprimir cómo se vería el código en main.py para acceder a estos datos precalculados\n",
    "    endpoint_name = endpoint_function.__name__\n",
    "    print(f\"\"\"\n",
    "@app.get(\"/{endpoint_name}/{{arg}}\")\n",
    "async def {endpoint_name}(arg: str):\n",
    "    try:\n",
    "        # Cargar los datos precalculados\n",
    "        data = pd.read_parquet('{output_filename}')\n",
    "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
    "        result = data.loc[arg]\n",
    "        return result.to_dict()\n",
    "    except KeyError:\n",
    "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "    \"\"\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# precalculate_and_save(mi_funcion, mi_dataframe, 'mi_columna', 'mi_archivo.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(desarrollador: str):\n",
    "    \"\"\"\n",
    "    Obtener la cantidad de ítems y el porcentaje de contenido gratuito por año, según la empresa desarrolladora.\n",
    "\n",
    "    Parameters:\n",
    "    desarrollador (str): El nombre de la empresa desarrolladora.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con los datos organizados por año.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por desarrollador\n",
    "    dev_df = developer_df[developer_df['developer'] == desarrollador]\n",
    "    # Agrupar los datos por año y calcular las métricas deseadas\n",
    "    yearly_data = dev_df.groupby('release_year').agg(\n",
    "        item_count=('item_id', 'count'), \n",
    "        free_content=('Free to Play', 'mean')\n",
    "    )\n",
    "    # Convertir la proporción de contenido gratuito a porcentaje\n",
    "    yearly_data['free_content'] = (yearly_data['free_content'] * 100).apply(lambda x: f'{x:.0f}%')\n",
    "    # Reorganizar el DataFrame y renombrar las columnas\n",
    "    yearly_data = yearly_data.reset_index().rename(columns={'release_year': 'Año', 'item_count': 'Cantidad de Items', 'free_content': 'Contenido Free'})\n",
    "    # Añadir la columna 'developer' al DataFrame\n",
    "    yearly_data['developer'] = desarrollador\n",
    "    \n",
    "    return yearly_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Cantidad de Items</th>\n",
       "      <th>Contenido Free</th>\n",
       "      <th>developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1475</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>586</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>234</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>51</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4240</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>449</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Año  Cantidad de Items Contenido Free developer\n",
       "0  2003               1475             0%   Ubisoft\n",
       "1  2004                586             0%   Ubisoft\n",
       "2  2005                234             0%   Ubisoft\n",
       "3  2007                 51             0%   Ubisoft\n",
       "4  2014               4240             0%   Ubisoft\n",
       "5  2016                449             0%   Ubisoft"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developer('Ubisoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userdata(User_id: str):\n",
    "    \"\"\"\n",
    "    Obtener información del usuario, incluyendo el dinero gastado, el porcentaje de recomendación y la cantidad de ítems.\n",
    "\n",
    "    Parameters:\n",
    "    User_id (str): El ID del usuario.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con la información del usuario.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por usuario\n",
    "    user_df = userdata_df[userdata_df['user_id'] == User_id]\n",
    "    # Filtrar los precios válidos (excluir -1)\n",
    "    valid_prices_df = user_df[user_df['price'] != -1]\n",
    "    # Calcular el total gastado\n",
    "    total_spent = valid_prices_df['price'].sum()\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    recommend_percentage = user_df['recommend'].mean() * 100\n",
    "    # Contar la cantidad de ítems\n",
    "    item_count = len(user_df)\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\"user_id\": User_id, \"Dinero gastado\": f\"{total_spent} USD\", \"% de recomendación\": f\"{recommend_percentage:.2f}%\", \"cantidad de items\": item_count}\n",
    "    # Convertir el diccionario result a un DataFrame\n",
    "    result_df = pd.DataFrame([result])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar -1 con 'Desconocido' en la columna 'release_year' antes de la iteración\n",
    "genre_playtime_df['release_year'] = genre_playtime_df['release_year'].replace(-1, 'Desconocido')\n",
    "\n",
    "def UserForGenre(genero: str):\n",
    "    \"\"\"\n",
    "    Obtener el usuario con más horas jugadas para un género dado y una lista de la acumulación de horas jugadas por año de lanzamiento.\n",
    "    \n",
    "    Parameters:\n",
    "    genero (str): El género del juego.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con la información del usuario y las horas jugadas por año.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por género\n",
    "    genre_df = genre_playtime_df[genre_playtime_df[genero] == 1]\n",
    "    # Calcular la suma de tiempo jugado por usuario\n",
    "    user_playtime = genre_df.groupby('user_id')['playtime_forever'].sum()\n",
    "    # Identificar el usuario con el máximo tiempo jugado\n",
    "    max_playtime_user = user_playtime.idxmax()\n",
    "    # Filtrar los datos por el usuario con el máximo tiempo jugado\n",
    "    user_df = genre_df[genre_df['user_id'] == max_playtime_user]\n",
    "    # Calcular la suma de tiempo jugado por año\n",
    "    user_year_playtime = user_df.groupby('release_year')['playtime_forever'].sum().reset_index()\n",
    "    # Convertir los datos a formato de diccionario\n",
    "    hours_played = user_year_playtime.to_dict('records')\n",
    "    # Crear un DataFrame con los resultados\n",
    "    result_df = pd.DataFrame([{\n",
    "        \"Genero\": genero,\n",
    "        \"Usuario con más horas jugadas\": max_playtime_user,\n",
    "        \"Horas jugadas\": str(hours_played)\n",
    "    }])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Crear una lista con todos los géneros\n",
    "all_genres = [\n",
    "        'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG',\n",
    "        'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle',\n",
    "        'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer',\n",
    "        'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult',\n",
    "        'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter',\n",
    "        'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox',\n",
    "        'Arcade'\n",
    "    ]\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los datos precalculados\n",
    "all_processed_data_list = []\n",
    "\n",
    "# Iterar sobre todos los géneros y precalcular los datos\n",
    "for genero in all_genres:\n",
    "    processed_data = UserForGenre(genero)\n",
    "    all_processed_data_list.append(processed_data)\n",
    "\n",
    "# Concatenar todos los datos procesados\n",
    "all_processed_data = pd.concat(all_processed_data_list)   \n",
    "\n",
    "all_processed_data.set_index('Genero', inplace=True)\n",
    "\n",
    "# Guardar todos los datos procesados en un archivo Parquet\n",
    "all_processed_data.to_parquet('../data/processed/UserForGenre_data.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genero</th>\n",
       "      <th>Usuario con más horas jugadas</th>\n",
       "      <th>Horas jugadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiplayer</td>\n",
       "      <td>Sp3ctre</td>\n",
       "      <td>[{'release_year': 1998, 'playtime_forever': 0}...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genero Usuario con más horas jugadas  \\\n",
       "0  Multiplayer                       Sp3ctre   \n",
       "\n",
       "                                       Horas jugadas  \n",
       "0  [{'release_year': 1998, 'playtime_forever': 0}...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserForGenre('Multiplayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_developer_year(año: int):\n",
    "    \"\"\"\n",
    "    Obtener el top 3 de desarrolladores con juegos más recomendados por usuarios para el año dado.\n",
    "    \n",
    "    Parameters:\n",
    "    año (int): El año de lanzamiento.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con el top 3 de desarrolladores.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por año\n",
    "    year_df = best_developer_year_df[best_developer_year_df['release_year'] == año]\n",
    "    # Filtrar los datos por recomendación\n",
    "    recommended_df = year_df[year_df['recommend'] == True]\n",
    "    # Contar las recomendaciones por desarrollador\n",
    "    developer_recommend_count = recommended_df.groupby('developer').size()\n",
    "    # Identificar el top 3 de desarrolladores\n",
    "    top_3_developers = developer_recommend_count.nlargest(3).index.tolist()\n",
    "\n",
    "    # Verificar la longitud de top_3_developers y llenar con 'N/A' si es necesario\n",
    "    while len(top_3_developers) < 3:\n",
    "        top_3_developers.append('N/A')\n",
    "\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\n",
    "        \"release_year\": [año],\n",
    "        \"Puesto 1\": [top_3_developers[0]],\n",
    "        \"Puesto 2\": [top_3_developers[1]],\n",
    "        \"Puesto 3\": [top_3_developers[2]]\n",
    "    }\n",
    "    # Crear un DataFrame con los resultados\n",
    "    result_df = pd.DataFrame(result)\n",
    "    # Convertir la columna release_year a entero\n",
    "    result_df['release_year'] = result_df['release_year'].astype(int)\n",
    "    return result_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer_reviews_analysis(desarrolladora: str):\n",
    "    \"\"\"\n",
    "    Obtener un análisis de las reseñas de una empresa desarrolladora específica.\n",
    "\n",
    "    Parameters:\n",
    "    desarrolladora (str): El nombre de la empresa desarrolladora.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con el análisis de las reseñas.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por desarrolladora\n",
    "    developer_df = developer_reviews_analysis_df[developer_reviews_analysis_df['developer'] == desarrolladora]\n",
    "    # Contar la cantidad de reseñas positivas y negativas\n",
    "    sentiment_counts = developer_df['sentiment_analysis'].value_counts()\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\"developer\": desarrolladora, \"Negative\": int(sentiment_counts.get(0, 0)), \"Positive\": int(sentiment_counts.get(2, 0))}\n",
    "    # Convertir el diccionario result a un DataFrame\n",
    "    result_df = pd.DataFrame([result])\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/developer/{arg}\")\n",
      "async def developer(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('developer_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Aplicar la función\n",
    "precalculate_and_save(developer, developer_df, 'developer', '../data/processed/developer_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/best_developer_year/{arg}\")\n",
      "async def best_developer_year(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('../data/processed/best_developer_year_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(best_developer_year, best_developer_year_df, 'release_year', '../data/processed/best_developer_year_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/developer_reviews_analysis/{arg}\")\n",
      "async def developer_reviews_analysis(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('developer_reviews_analysis_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(developer_reviews_analysis, developer_reviews_analysis_df, 'developer', '../data/processed/developer_reviews_analysis_data.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/userdata/{arg}\")\n",
      "async def userdata(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('userdata_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(userdata, userdata_df, 'user_id', '../data/processed/userdata_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Funciones auxiliares para generar características y calcular similitud del coseno\n",
    "def generate_features(df, group_by_col, feature_cols):\n",
    "    feature_series_list = [df.groupby(group_by_col)[col].agg(['sum', 'mean']) for col in feature_cols]\n",
    "    features_df = pd.concat(feature_series_list, axis=1)\n",
    "    return features_df\n",
    "\n",
    "def compute_cosine_similarity(features_df):\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features_df)\n",
    "    cosine_sim_matrix = cosine_similarity(features_scaled, features_scaled)\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=features_df.index, columns=features_df.index)\n",
    "    return cosine_sim_df\n",
    "\n",
    "def precalculate_similarity(df, group_by_col, feature_cols, output_filename):\n",
    "    features_df = generate_features(df, group_by_col, feature_cols)\n",
    "    cosine_sim_df = compute_cosine_similarity(features_df)\n",
    "    cosine_sim_df.to_parquet(output_filename)\n",
    "\n",
    "# Funciones para calcular recomendaciones\n",
    "def calcular_recomendaciones_juego(df, game_cosine_sim_df, item_id):\n",
    "    sim_scores = game_cosine_sim_df[str(item_id)]\n",
    "    recommended_games_ids = sim_scores.sort_values(ascending=False)[1:6].index\n",
    "    recommended_games_names = df.set_index('item_id').loc[recommended_games_ids, 'app_name'].unique()\n",
    "    result = {\"Juegos recomendados\": [recommended_games_names.tolist()]}\n",
    "    return pd.DataFrame(result, index=[item_id])\n",
    "\n",
    "def calcular_recomendaciones_usuario(df, user_cosine_sim_df, user_id):\n",
    "    sim_scores = user_cosine_sim_df[str(user_id)]\n",
    "    similar_users = sim_scores.sort_values(ascending=False)[1:]\n",
    "    similar_users_list = similar_users.index.tolist()\n",
    "    recommended_games_ids = df[df['user_id'].isin(similar_users_list)]['item_id'].unique()\n",
    "    recommended_games_ids = sorted(recommended_games_ids, key=lambda x: similar_users_list.index(df[df['item_id'] == x]['user_id'].iloc[0]))\n",
    "    recommended_game_names = df.set_index('item_id').loc[recommended_games_ids[:5], 'app_name'].unique()\n",
    "    result = {\"Juegos recomendados\": [recommended_game_names.tolist()]}\n",
    "    return pd.DataFrame(result, index=[user_id])\n",
    "\n",
    "def calcular_recomendaciones(df, cosine_sim_df, ids, tipo):\n",
    "    recommendations = []\n",
    "    for id in ids:\n",
    "        if tipo == 'juego':\n",
    "            recommendations.append(calcular_recomendaciones_juego(df, cosine_sim_df, id))\n",
    "        elif tipo == 'usuario':\n",
    "            recommendations.append(calcular_recomendaciones_usuario(df, cosine_sim_df, id))\n",
    "    return pd.concat(recommendations)\n",
    "\n",
    "# Precalcular similitudes para juegos y usuarios\n",
    "game_features_df = generate_features(reduced_df, 'item_id', ['playtime_forever', 'recommend', 'sentiment_analysis'])\n",
    "user_features_df = generate_features(final_merged_df, 'user_id', ['playtime_forever', 'sentiment_analysis', 'recommend'])\n",
    "\n",
    "game_cosine_sim_df = compute_cosine_similarity(game_features_df)\n",
    "user_cosine_sim_df = compute_cosine_similarity(user_features_df)\n",
    "\n",
    "# Obtén los valores únicos para los juegos y usuarios\n",
    "unique_game_ids = reduced_df['item_id'].unique()\n",
    "unique_user_ids = final_merged_df['user_id'].unique()\n",
    "\n",
    "# Calcular las recomendaciones\n",
    "recomendaciones_juego = calcular_recomendaciones(reduced_df, game_cosine_sim_df, unique_game_ids, 'juego')\n",
    "recomendaciones_usuario = calcular_recomendaciones(final_merged_df, user_cosine_sim_df, unique_user_ids, 'usuario')\n",
    "\n",
    "# Guardar los resultados en archivos Parquet\n",
    "recomendaciones_juego.to_parquet('../data/processed/recomendaciones_juego.parquet')\n",
    "recomendaciones_usuario.to_parquet('../data/processed/recomendaciones_usuario.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
