{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los dataframes desde archivos parquet\n",
    "df_items = pd.read_parquet('../data/interim/parquet/final_items.parquet')\n",
    "df_games = pd.read_parquet('../data/interim/parquet/final_games.parquet')\n",
    "df_reviews = pd.read_parquet('../data/interim/parquet/final_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que la columna 'item_id' sea de tipo int\n",
    "df_items['item_id'] = df_items['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer merge: unir df_items y df_games en 'item_id' y 'id'\n",
    "merged_df_1 = pd.merge(df_items, df_games, left_on='item_id', right_on='id')\n",
    "\n",
    "# Segundo merge: unir el DataFrame resultante con df_reviews en 'user_id'\n",
    "final_merged_df = pd.merge(merged_df_1, df_reviews, on='user_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna item_id_y y renombrar item_id_x a item_id\n",
    "final_merged_df = final_merged_df.drop(columns=['item_id_y']).rename(columns={'item_id_x': 'item_id'})\n",
    "\n",
    "# Definir el nuevo orden de las columnas (mover las columnas de géneros al final para una mejor organización)\n",
    "\n",
    "new_column_order = [\n",
    "    'user_id', 'steam_id', 'item_id', 'developer', 'item_name', 'playtime_forever',\n",
    "    'app_name', 'id', 'price', 'release_year', 'funny', 'posted', \n",
    "    'helpful', 'recommend', 'sentiment_analysis',\n",
    "    # Mover las columnas de géneros al final\n",
    "    'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG',\n",
    "    'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle',\n",
    "    'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer',\n",
    "    'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult',\n",
    "    'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter',\n",
    "    'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox',\n",
    "    'Arcade'\n",
    "]\n",
    "\n",
    "# Reorganizar las columnas\n",
    "final_merged_df = final_merged_df.reindex(columns=new_column_order)\n",
    "\n",
    "# Seleccionar las columnas relevantes para análisis de género y tiempo de juego\n",
    "genre_playtime_df = final_merged_df[['user_id', 'playtime_forever', 'release_year', 'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG', 'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle', 'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer', 'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult', 'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter', 'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox', 'Arcade']]\n",
    "\n",
    "# Crear una copia y asegurando que 'release_year' es de tipo int\n",
    "genre_playtime_df = genre_playtime_df.copy()\n",
    "genre_playtime_df['release_year'] = genre_playtime_df['release_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando dataframes para análisis específicos\n",
    "\n",
    "recommendations_df = final_merged_df[['app_name', 'release_year', 'recommend', 'sentiment_analysis']]\n",
    "\n",
    "developer_df = final_merged_df[['developer', 'item_id', 'release_year', 'Free to Play']]\n",
    "\n",
    "userdata_df = final_merged_df[['user_id', 'price', 'recommend']]\n",
    "\n",
    "best_developer_year_df = final_merged_df[['developer', 'release_year', 'recommend']]\n",
    "\n",
    "developer_reviews_analysis_df = final_merged_df[['developer', 'sentiment_analysis']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save(endpoint_function, dataframe, column, output_filename):\n",
    "    \"\"\"\n",
    "    Precalcula datos utilizando una función de endpoint específica y los guarda en un archivo Parquet.\n",
    "    \n",
    "    Parameters:\n",
    "    endpoint_function (function): La función que procesará los datos.\n",
    "    dataframe (pd.DataFrame): El DataFrame que contiene los datos a procesar.\n",
    "    column (str): La columna que contiene los valores únicos para procesar.\n",
    "    output_filename (str): El nombre del archivo donde se guardarán los datos procesados.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Obtener los valores únicos en la columna especificada\n",
    "    unique_values = dataframe[column].unique()\n",
    "    \n",
    "    # Utilizar ThreadPoolExecutor para ejecutar las operaciones en paralelo\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Mapear la función endpoint a cada valor único\n",
    "        all_processed_data_list = list(executor.map(endpoint_function, unique_values))\n",
    "        \n",
    "    # Concatenar todos los datos procesados\n",
    "    all_processed_data = pd.concat(all_processed_data_list)\n",
    "    \n",
    "    # Establecer el índice del DataFrame resultante a la columna especificada\n",
    "    all_processed_data.set_index(column, inplace=True)\n",
    "    \n",
    "    # Guardar todos los datos procesados en un archivo Parquet\n",
    "    all_processed_data.to_parquet(output_filename)\n",
    "    \n",
    "    # Imprimir cómo se vería el código en main.py para acceder a estos datos precalculados\n",
    "    endpoint_name = endpoint_function.__name__\n",
    "    print(f\"\"\"\n",
    "@app.get(\"/{endpoint_name}/{{arg}}\")\n",
    "async def {endpoint_name}(arg: str):\n",
    "    try:\n",
    "        # Cargar los datos precalculados\n",
    "        data = pd.read_parquet('{output_filename}')\n",
    "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
    "        result = data.loc[arg]\n",
    "        return result.to_dict()\n",
    "    except KeyError:\n",
    "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "    \"\"\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# precalculate_and_save(mi_funcion, mi_dataframe, 'mi_columna', 'mi_archivo.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(desarrollador: str):\n",
    "    \"\"\"\n",
    "    Obtener la cantidad de ítems y el porcentaje de contenido gratuito por año, según la empresa desarrolladora.\n",
    "\n",
    "    Parameters:\n",
    "    desarrollador (str): El nombre de la empresa desarrolladora.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con los datos organizados por año.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por desarrollador\n",
    "    dev_df = developer_df[developer_df['developer'] == desarrollador]\n",
    "    # Agrupar los datos por año y calcular las métricas deseadas\n",
    "    yearly_data = dev_df.groupby('release_year').agg(\n",
    "        item_count=('item_id', 'count'), \n",
    "        free_content=('Free to Play', 'mean')\n",
    "    )\n",
    "    # Convertir la proporción de contenido gratuito a porcentaje\n",
    "    yearly_data['free_content'] = (yearly_data['free_content'] * 100).apply(lambda x: f'{x:.0f}%')\n",
    "    # Reorganizar el DataFrame y renombrar las columnas\n",
    "    yearly_data = yearly_data.reset_index().rename(columns={'release_year': 'Año', 'item_count': 'Cantidad de Items', 'free_content': 'Contenido Free'})\n",
    "    # Añadir la columna 'developer' al DataFrame\n",
    "    yearly_data['developer'] = desarrollador\n",
    "    \n",
    "    return yearly_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Cantidad de Items</th>\n",
       "      <th>Contenido Free</th>\n",
       "      <th>developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1475</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>586</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>234</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>51</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4240</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>449</td>\n",
       "      <td>0%</td>\n",
       "      <td>Ubisoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Año  Cantidad de Items Contenido Free developer\n",
       "0  2003               1475             0%   Ubisoft\n",
       "1  2004                586             0%   Ubisoft\n",
       "2  2005                234             0%   Ubisoft\n",
       "3  2007                 51             0%   Ubisoft\n",
       "4  2014               4240             0%   Ubisoft\n",
       "5  2016                449             0%   Ubisoft"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developer('Ubisoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userdata(User_id: str):\n",
    "    \"\"\"\n",
    "    Obtener información del usuario, incluyendo el dinero gastado, el porcentaje de recomendación y la cantidad de ítems.\n",
    "\n",
    "    Parameters:\n",
    "    User_id (str): El ID del usuario.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con la información del usuario.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por usuario\n",
    "    user_df = userdata_df[userdata_df['user_id'] == User_id]\n",
    "    # Filtrar los precios válidos (excluir -1)\n",
    "    valid_prices_df = user_df[user_df['price'] != -1]\n",
    "    # Calcular el total gastado\n",
    "    total_spent = valid_prices_df['price'].sum()\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    recommend_percentage = user_df['recommend'].mean() * 100\n",
    "    # Contar la cantidad de ítems\n",
    "    item_count = len(user_df)\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\"user_id\": User_id, \"Dinero gastado\": f\"{total_spent} USD\", \"% de recomendación\": f\"{recommend_percentage:.2f}%\", \"cantidad de items\": item_count}\n",
    "    # Convertir el diccionario result a un DataFrame\n",
    "    result_df = pd.DataFrame([result])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar -1 con 'Desconocido' en la columna 'release_year' antes de la iteración\n",
    "genre_playtime_df['release_year'] = genre_playtime_df['release_year'].replace(-1, 'Desconocido')\n",
    "\n",
    "def UserForGenre(genero: str):\n",
    "    \"\"\"\n",
    "    Obtener el usuario con más horas jugadas para un género dado y una lista de la acumulación de horas jugadas por año de lanzamiento.\n",
    "    \n",
    "    Parameters:\n",
    "    genero (str): El género del juego.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con la información del usuario y las horas jugadas por año.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por género\n",
    "    genre_df = genre_playtime_df[genre_playtime_df[genero] == 1]\n",
    "    # Calcular la suma de tiempo jugado por usuario\n",
    "    user_playtime = genre_df.groupby('user_id')['playtime_forever'].sum()\n",
    "    # Identificar el usuario con el máximo tiempo jugado\n",
    "    max_playtime_user = user_playtime.idxmax()\n",
    "    # Filtrar los datos por el usuario con el máximo tiempo jugado\n",
    "    user_df = genre_df[genre_df['user_id'] == max_playtime_user]\n",
    "    # Calcular la suma de tiempo jugado por año\n",
    "    user_year_playtime = user_df.groupby('release_year')['playtime_forever'].sum().reset_index()\n",
    "    # Convertir los datos a formato de diccionario\n",
    "    hours_played = user_year_playtime.to_dict('records')\n",
    "    # Crear un DataFrame con los resultados\n",
    "    result_df = pd.DataFrame([{\n",
    "        \"Genero\": genero,\n",
    "        \"Usuario con más horas jugadas\": max_playtime_user,\n",
    "        \"Horas jugadas\": str(hours_played)\n",
    "    }])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Crear una lista con todos los géneros\n",
    "all_genres = [\n",
    "        'Indie', 'Action', 'Adventure', 'Casual', 'Simulation', 'Strategy', 'RPG',\n",
    "        'Singleplayer', 'Free to Play', 'Multiplayer', 'Great Soundtrack', 'Puzzle',\n",
    "        'Early Access', '2D', 'Atmospheric', 'VR', 'Sports', 'Platformer',\n",
    "        'Story Rich', 'Sci-fi', 'Fantasy', 'Horror', 'Open World', 'Difficult',\n",
    "        'Anime', 'Massively Multiplayer', 'Pixel Graphics', 'Co-op', 'Shooter',\n",
    "        'Racing', 'Female Protagonist', 'Funny', 'First-Person', 'FPS', 'Sandbox',\n",
    "        'Arcade'\n",
    "    ]\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los datos precalculados\n",
    "all_processed_data_list = []\n",
    "\n",
    "# Iterar sobre todos los géneros y precalcular los datos\n",
    "for genero in all_genres:\n",
    "    processed_data = UserForGenre(genero)\n",
    "    all_processed_data_list.append(processed_data)\n",
    "\n",
    "# Concatenar todos los datos procesados\n",
    "all_processed_data = pd.concat(all_processed_data_list)   \n",
    "\n",
    "all_processed_data.set_index('Genero', inplace=True)\n",
    "\n",
    "# Guardar todos los datos procesados en un archivo Parquet\n",
    "all_processed_data.to_parquet('../data/processed/UserForGenre_data.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genero</th>\n",
       "      <th>Usuario con más horas jugadas</th>\n",
       "      <th>Horas jugadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiplayer</td>\n",
       "      <td>Sp3ctre</td>\n",
       "      <td>[{'release_year': 1998, 'playtime_forever': 0}...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genero Usuario con más horas jugadas  \\\n",
       "0  Multiplayer                       Sp3ctre   \n",
       "\n",
       "                                       Horas jugadas  \n",
       "0  [{'release_year': 1998, 'playtime_forever': 0}...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserForGenre('Multiplayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_developer_year(año: int):\n",
    "    \"\"\"\n",
    "    Obtener el top 3 de desarrolladores con juegos más recomendados por usuarios para el año dado.\n",
    "    \n",
    "    Parameters:\n",
    "    año (int): El año de lanzamiento.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con el top 3 de desarrolladores.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por año\n",
    "    year_df = best_developer_year_df[best_developer_year_df['release_year'] == año]\n",
    "    # Filtrar los datos por recomendación\n",
    "    recommended_df = year_df[year_df['recommend'] == True]\n",
    "    # Contar las recomendaciones por desarrollador\n",
    "    developer_recommend_count = recommended_df.groupby('developer').size()\n",
    "    # Identificar el top 3 de desarrolladores\n",
    "    top_3_developers = developer_recommend_count.nlargest(3).index.tolist()\n",
    "\n",
    "    # Verificar la longitud de top_3_developers y llenar con 'N/A' si es necesario\n",
    "    while len(top_3_developers) < 3:\n",
    "        top_3_developers.append('N/A')\n",
    "\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\n",
    "        \"release_year\": [año],\n",
    "        \"Puesto 1\": [top_3_developers[0]],\n",
    "        \"Puesto 2\": [top_3_developers[1]],\n",
    "        \"Puesto 3\": [top_3_developers[2]]\n",
    "    }\n",
    "    # Crear un DataFrame con los resultados\n",
    "    result_df = pd.DataFrame(result)\n",
    "    # Convertir la columna release_year a entero\n",
    "    result_df['release_year'] = result_df['release_year'].astype(int)\n",
    "    return result_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer_reviews_analysis(desarrolladora: str):\n",
    "    \"\"\"\n",
    "    Obtener un análisis de las reseñas de una empresa desarrolladora específica.\n",
    "\n",
    "    Parameters:\n",
    "    desarrolladora (str): El nombre de la empresa desarrolladora.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con el análisis de las reseñas.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos por desarrolladora\n",
    "    developer_df = developer_reviews_analysis_df[developer_reviews_analysis_df['developer'] == desarrolladora]\n",
    "    # Contar la cantidad de reseñas positivas y negativas\n",
    "    sentiment_counts = developer_df['sentiment_analysis'].value_counts()\n",
    "    # Crear un diccionario con los resultados\n",
    "    result = {\"developer\": desarrolladora, \"Negative\": int(sentiment_counts.get(0, 0)), \"Positive\": int(sentiment_counts.get(2, 0))}\n",
    "    # Convertir el diccionario result a un DataFrame\n",
    "    result_df = pd.DataFrame([result])\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/developer/{arg}\")\n",
      "async def developer(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('developer_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Aplicar la función\n",
    "precalculate_and_save(developer, developer_df, 'developer', '../data/processed/developer_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/best_developer_year/{arg}\")\n",
      "async def best_developer_year(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('../data/processed/best_developer_year_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(best_developer_year, best_developer_year_df, 'release_year', '../data/processed/best_developer_year_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/developer_reviews_analysis/{arg}\")\n",
      "async def developer_reviews_analysis(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('developer_reviews_analysis_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(developer_reviews_analysis, developer_reviews_analysis_df, 'developer', '../data/processed/developer_reviews_analysis_data.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@app.get(\"/userdata/{arg}\")\n",
      "async def userdata(arg: str):\n",
      "    try:\n",
      "        # Cargar los datos precalculados\n",
      "        data = pd.read_parquet('userdata_data.parquet')\n",
      "        # Suponiendo que los datos están indexados por el argumento proporcionado\n",
      "        result = data.loc[arg]\n",
      "        return result.to_dict()\n",
      "    except KeyError:\n",
      "        raise HTTPException(status_code=404, detail=\"No se encontraron datos para el argumento proporcionado.\")\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=400, detail=str(e))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "precalculate_and_save(userdata, userdata_df, 'user_id', '../data/processed/userdata_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funciones auxiliares para generar características y calcular similitud del coseno\n",
    "def generate_features(df, group_by_col, feature_cols):\n",
    "    \"\"\"\n",
    "    Generar características a partir de un DataFrame agrupando por una columna y calculando la suma y la media de otras columnas.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): El DataFrame original.\n",
    "    group_by_col (str): El nombre de la columna por la cual agrupar.\n",
    "    feature_cols (list): Una lista de nombres de columnas para calcular características.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con las características generadas.\n",
    "    \"\"\"\n",
    "    feature_series_list = [df.groupby(group_by_col)[col].agg(['sum', 'mean']) for col in feature_cols]\n",
    "    features_df = pd.concat(feature_series_list, axis=1)\n",
    "    return features_df\n",
    "\n",
    "def compute_cosine_similarity(features_df):\n",
    "    \"\"\"\n",
    "    Calcular la matriz de similitud del coseno para un DataFrame de características.\n",
    "\n",
    "    Parameters:\n",
    "    features_df (pd.DataFrame): El DataFrame de características.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con la matriz de similitud del coseno.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features_df)\n",
    "    \n",
    "    # Aplicando PCA para reducir dimensiones\n",
    "    pca = PCA(n_components=0.95)  # Conserva el 95% de la varianza\n",
    "    features_reduced = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    cosine_sim_matrix = cosine_similarity(features_reduced, features_reduced)\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=features_df.index, columns=features_df.index)\n",
    "    return cosine_sim_df\n",
    "\n",
    "def precalculate_similarity(df, group_by_col, feature_cols, output_filename):\n",
    "    \"\"\"\n",
    "    Precalcular la matriz de similitud del coseno y guardarla en un archivo Parquet.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): El DataFrame original.\n",
    "    group_by_col (str): El nombre de la columna por la cual agrupar.\n",
    "    feature_cols (list): Una lista de nombres de columnas para calcular características.\n",
    "    output_filename (str): El nombre del archivo de salida.\n",
    "\n",
    "    \"\"\"\n",
    "    features_df = generate_features(df, group_by_col, feature_cols)\n",
    "    cosine_sim_df = compute_cosine_similarity(features_df)\n",
    "    cosine_sim_df.to_parquet(output_filename)\n",
    "    \n",
    "def get_index_or_default(value, lst, default=-1):\n",
    "    \"\"\"\n",
    "    Obtiene el índice de un valor en una lista, o retorna un valor predeterminado si el valor no se encuentra en la lista.\n",
    "\n",
    "    Parameters:\n",
    "    value (any): El valor cuyo índice se desea obtener.\n",
    "    lst (list): La lista en la que se buscará el valor.\n",
    "    default (int, optional): El valor predeterminado a retornar si el valor no se encuentra en la lista. Por defecto es -1.\n",
    "\n",
    "    Returns:\n",
    "    int: El índice del valor en la lista, o el valor predeterminado si el valor no se encuentra en la lista.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return lst.index(value)\n",
    "    except ValueError:\n",
    "        return default\n",
    "    \n",
    "# def calcular_recomendaciones_paralelo(df, cosine_sim_df, ids, tipo):\n",
    "#     \"\"\"\n",
    "#     Calcula recomendaciones de juegos o usuarios en paralelo, basadas en similitud del coseno.\n",
    "    \n",
    "#     Esta función itera sobre un conjunto de IDs de juegos o usuarios, y genera recomendaciones\n",
    "#     utilizando la similitud del coseno entre elementos, dependiendo del tipo especificado \n",
    "#     (juego o usuario). La ejecución se paraleliza para mejorar el rendimiento.\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): DataFrame que contiene los datos de los juegos o usuarios.\n",
    "#     cosine_sim_df (pd.DataFrame): DataFrame que contiene la matriz de similitud del coseno.\n",
    "#     ids (iterable): Una lista o array de IDs de juegos o usuarios para los cuales se deben calcular las recomendaciones.\n",
    "#     tipo (str): Tipo de recomendación a calcular, 'juego' para recomendaciones de juegos y 'usuario' para recomendaciones de usuarios.\n",
    "\n",
    "#     Returns:\n",
    "#     pd.DataFrame: Un DataFrame que contiene las recomendaciones generadas para cada ID en `ids`.\n",
    "#     \"\"\"\n",
    "#     recommendations = Parallel(n_jobs=-1)(\n",
    "#         delayed(calcular_recomendaciones)(df, cosine_sim_df, id, tipo) for id in ids\n",
    "#     )\n",
    "#     return pd.concat(recommendations)\n",
    "\n",
    "\n",
    "# Funciones para calcular recomendaciones\n",
    "def calcular_recomendaciones_juego(df, game_cosine_sim_matrix, item_id):\n",
    "    \"\"\"\n",
    "    Calcular recomendaciones de juegos basadas en la similitud del coseno para un juego específico.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): El DataFrame original con información de los juegos.\n",
    "    game_cosine_sim_matrix (numpy.ndarray): Matriz de similitud del coseno precalculada para los juegos.\n",
    "    item_id (int): El ID del juego para el cual se deben calcular las recomendaciones.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con los juegos recomendados.\n",
    "    \"\"\"\n",
    "    # Obtén los índices de los juegos en el DataFrame.\n",
    "    # Esto es necesario para mapear el índice en la matriz de similitud del coseno al ID del juego.\n",
    "    game_indices = df['item_id'].reset_index(drop=True)\n",
    "    game_index = game_indices[game_indices == item_id].index[0]\n",
    "\n",
    "    # Obtén las puntuaciones de similitud para el juego específico desde la matriz de similitud del coseno.\n",
    "    sim_scores = game_cosine_sim_matrix[game_index]\n",
    "\n",
    "    # Convierte las puntuaciones de similitud a una Serie de pandas para facilidad de manejo,\n",
    "    # y ordena las puntuaciones de mayor a menor.\n",
    "    sim_scores_series = pd.Series(sim_scores, index=game_indices)\n",
    "    recommended_games_indices = sim_scores_series.sort_values(ascending=False)[1:6].index\n",
    "\n",
    "    # Obtén los nombres de los juegos recomendados utilizando los índices recomendados.\n",
    "    recommended_games_names = df.set_index('item_id').loc[recommended_games_indices, 'app_name'].unique()\n",
    "\n",
    "    # Crea un DataFrame para presentar los resultados.\n",
    "    result = {\"Juegos recomendados\": [recommended_games_names.tolist()]}\n",
    "    return pd.DataFrame(result, index=[item_id])\n",
    "\n",
    "\n",
    "\n",
    "def calcular_recomendaciones_usuario(df, user_cosine_sim_matrix, user_id):\n",
    "    \"\"\"\n",
    "    Calcular recomendaciones de juegos basadas en la similitud del coseno para un usuario específico.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): El DataFrame original con información de los usuarios y juegos.\n",
    "    user_cosine_sim_matrix (numpy.ndarray): Matriz de similitud del coseno precalculada para los usuarios.\n",
    "    user_id (str): El ID del usuario para el cual se deben calcular las recomendaciones.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame con los juegos recomendados.\n",
    "    \"\"\"\n",
    "    # Obtener el índice del usuario en la matriz de similitud del coseno\n",
    "    print('adentro')\n",
    "    user_ids = df.index.get_level_values('user_id').unique()  # Asegúrate de que los IDs sean únicos\n",
    "    if user_id not in user_ids:\n",
    "        raise ValueError(f\"user_id {user_id} not found in DataFrame index.\")\n",
    "    \n",
    "    # Encuentra la posición del user_id en la lista única de user_ids\n",
    "    user_index = np.where(user_ids == user_id)[0][0]\n",
    "    \n",
    "    print('user_ids')\n",
    "\n",
    "    # Obtener las puntuaciones de similitud para el usuario específico\n",
    "    sim_scores = user_cosine_sim_matrix[user_index]\n",
    "    print('sim_scores')\n",
    "\n",
    "    # Ordenar las puntuaciones y obtener índices de usuarios similares\n",
    "    similar_users_indices = np.argsort(sim_scores)[::-1][1:]  # Excluye el primer elemento que es el mismo usuario\n",
    "    print('similar_users_indices')\n",
    "    \n",
    "    # Obtener los índices de juego de los usuarios similares\n",
    "    user_ids = df.index.get_level_values('user_id')\n",
    "    similar_users_ids = user_ids[similar_users_indices]\n",
    "    similar_users_game_indices = df.index.get_level_values('item_id')[user_ids.isin(similar_users_ids)]\n",
    "    print('similar_users_game_indices')\n",
    "        \n",
    "    # Obtener los nombres de los juegos recomendados\n",
    "    user_game_df = df.loc[(slice(None), similar_users_game_indices), :]\n",
    "    recommended_game_names = user_game_df['app_name'].unique()\n",
    "    \n",
    "    result = {\"Juegos recomendados\": [recommended_game_names.tolist()]}\n",
    "    return pd.DataFrame(result, index=[user_id])\n",
    "\n",
    "\n",
    "\n",
    "def calcular_recomendaciones(df, cosine_sim_df, ids, tipo):\n",
    "    \"\"\"\n",
    "    Calcula recomendaciones de juegos o usuarios basadas en similitud del coseno.\n",
    "    \n",
    "    Esta función itera sobre un conjunto de IDs de juegos o usuarios, y genera recomendaciones\n",
    "    utilizando la similitud del coseno entre elementos, dependiendo del tipo especificado \n",
    "    (juego o usuario).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame que contiene los datos de los juegos o usuarios.\n",
    "    cosine_sim_df (pd.DataFrame): DataFrame que contiene la matriz de similitud del coseno.\n",
    "    ids (iterable): Una lista o array de IDs de juegos o usuarios para los cuales se deben calcular las recomendaciones.\n",
    "    tipo (str): Tipo de recomendación a calcular, 'juego' para recomendaciones de juegos y 'usuario' para recomendaciones de usuarios.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame que contiene las recomendaciones generadas para cada ID en `ids`.\n",
    "    \"\"\"\n",
    "    if tipo == 'juego':\n",
    "        func = calcular_recomendaciones_juego\n",
    "    elif tipo == 'usuario':\n",
    "        func = calcular_recomendaciones_usuario\n",
    "    \n",
    "    # Lista para almacenar los DataFrames de recomendaciones\n",
    "    recommendations = []\n",
    "\n",
    "    # Bucle for convencional para iterar sobre cada ID\n",
    "    for id in ids:\n",
    "        # Llamada a la función de recomendación y almacenamiento del DataFrame resultante\n",
    "        recommendations.append(func(df, cosine_sim_df, id))\n",
    "    \n",
    "    # Concatenación de todos los DataFrames de recomendaciones en un solo DataFrame\n",
    "    return pd.concat(recommendations) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "games_reduced_df = final_merged_df[['item_id', 'app_name', 'playtime_forever', 'recommend', 'sentiment_analysis']].drop_duplicates(subset='item_id')\n",
    "user_reduced_df = final_merged_df[['user_id', 'item_id', 'playtime_forever', 'recommend', 'sentiment_analysis', 'app_name']]\n",
    "\n",
    "# Obtener los valores únicos para los juegos y usuarios antes de cambiar los índices\n",
    "unique_game_ids = games_reduced_df['item_id'].unique()\n",
    "unique_user_ids = user_reduced_df['user_id'].unique()\n",
    "\n",
    "# Asegurar de que 'user_id' e 'item_id' estén indexados para una búsqueda más rápida\n",
    "user_reduced_df = user_reduced_df.set_index(['user_id', 'item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Precalcular similitudes para juegos y usuarios\n",
    "game_features_df = generate_features(games_reduced_df, 'item_id', ['playtime_forever', 'recommend', 'sentiment_analysis'])\n",
    "user_features_df = generate_features(user_reduced_df, 'user_id', ['playtime_forever', 'sentiment_analysis', 'recommend'])\n",
    "\n",
    "game_cosine_sim_df = compute_cosine_similarity(game_features_df)\n",
    "user_cosine_sim_df = compute_cosine_similarity(user_features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8994 entries, 10 to 530720\n",
      "Columns: 8994 entries, 10 to 530720\n",
      "dtypes: float64(8994)\n",
      "memory usage: 617.4 MB\n"
     ]
    }
   ],
   "source": [
    "game_cosine_sim_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_cosine_sim_df = game_cosine_sim_df.astype('float32')\n",
    "user_cosine_sim_df = user_cosine_sim_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# game_cosine_sim_sparse = csr_matrix(game_cosine_sim_df.values)\n",
    "# user_cosine_sim_sparse = csr_matrix(user_cosine_sim_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Para matrices densas\n",
    "np.save('game_cosine_sim.npy', game_cosine_sim_df.values)\n",
    "np.save('user_cosine_sim.npy', user_cosine_sim_df.values)\n",
    "\n",
    "# # Para matrices esparsas\n",
    "# np.savez('game_cosine_sim.npz', game_cosine_sim_sparse)\n",
    "# np.savez('user_cosine_sim.npz', user_cosine_sim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las matrices de similitud del coseno desde los archivos binarios\n",
    "game_cosine_sim_matrix = np.load('game_cosine_sim.npy')\n",
    "user_cosine_sim_matrix = np.load('user_cosine_sim.npy')\n",
    "\n",
    "# O si estás utilizando matrices esparsas\n",
    "# game_cosine_sim_sparse = np.load('game_cosine_sim.npz')['arr_0']\n",
    "# user_cosine_sim_sparse = np.load('user_cosine_sim.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular las recomendaciones y guardar los resultados en archivos Parquet\n",
    "recomendaciones_juego = calcular_recomendaciones(games_reduced_df, game_cosine_sim_matrix, unique_game_ids, 'juego')\n",
    "recomendaciones_juego.to_parquet('../data/processed/recomendaciones_juego.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adentro\n",
      "user_ids\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 22576 but corresponding boolean dimension is 6562912",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Compumar\\Documents\\Henry\\PI_ML_OPS1_FT16\\notebooks\\merge.ipynb Celda 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m recomendaciones_usuario \u001b[39m=\u001b[39m calcular_recomendaciones(user_reduced_df, user_cosine_sim_matrix, unique_user_ids, \u001b[39m'\u001b[39;49m\u001b[39musuario\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m recomendaciones_usuario\u001b[39m.\u001b[39mto_parquet(\u001b[39m'\u001b[39m\u001b[39m../data/processed/recomendaciones_usuario.parquet\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Compumar\\Documents\\Henry\\PI_ML_OPS1_FT16\\notebooks\\merge.ipynb Celda 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39m# Bucle for convencional para iterar sobre cada ID\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=205'>206</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m     \u001b[39m# Llamada a la función de recomendación y almacenamiento del DataFrame resultante\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=207'>208</a>\u001b[0m     recommendations\u001b[39m.\u001b[39mappend(func(df, cosine_sim_df, \u001b[39mid\u001b[39;49m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=209'>210</a>\u001b[0m \u001b[39m# Concatenación de todos los DataFrames de recomendaciones en un solo DataFrame\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=210'>211</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat(recommendations)\n",
      "\u001b[1;32mc:\\Users\\Compumar\\Documents\\Henry\\PI_ML_OPS1_FT16\\notebooks\\merge.ipynb Celda 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39muser_ids\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39m# Obtener las puntuaciones de similitud para el usuario específico\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m sim_scores \u001b[39m=\u001b[39m user_cosine_sim_matrix[user_index]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msim_scores\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Compumar/Documents/Henry/PI_ML_OPS1_FT16/notebooks/merge.ipynb#X36sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39m# Ordenar las puntuaciones y obtener índices de usuarios similares\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 22576 but corresponding boolean dimension is 6562912"
     ]
    }
   ],
   "source": [
    "recomendaciones_usuario = calcular_recomendaciones(user_reduced_df, user_cosine_sim_matrix, unique_user_ids, 'usuario')\n",
    "recomendaciones_usuario.to_parquet('../data/processed/recomendaciones_usuario.parquet')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
